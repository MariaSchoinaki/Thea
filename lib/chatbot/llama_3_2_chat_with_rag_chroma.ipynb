{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg4wNf3U17Sc"
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZlIK80P17Se",
    "outputId": "21d58d24-6735-4960-e707-e1c98b02dd15"
   },
   "outputs": [],
   "source": [
    "# --- Core Python package tools ---\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# --- Torch & GPU ---\n",
    "!pip install torch\n",
    "!pip install faiss-gpu\n",
    "\n",
    "# --- Huggingface ecosystem (models, transformers, datasets, quant, etc.) ---\n",
    "!pip install git+https://github.com/huggingface/transformers  # Latest transformers\n",
    "!pip install transformers[agents]                             # Agents utilities\n",
    "!pip install git+https://github.com/huggingface/peft.git      # Parameter Efficient Fine-Tuning\n",
    "!pip install git+https://github.com/huggingface/accelerate.git\n",
    "!pip install git+https://github.com/huggingface/trl.git       # Transformer Reinforcement Learning\n",
    "!pip install -U sentence-transformers                         # Embeddings\n",
    "!pip install datasets                                         # Datasets library\n",
    "!pip install -i https://pypi.org/simple/ bitsandbytes         # 4-bit/8-bit quantization support\n",
    "\n",
    "# --- LangChain (core + community + huggingface + chroma) ---\n",
    "!pip install -U langchain                                     # Core\n",
    "!pip install -U langchain-community                           # Community extensions\n",
    "!pip install -U langchain-huggingface                         # HuggingFace connector\n",
    "!pip install langchain-chroma                                 # Chroma DB integration\n",
    "!pip install langchainhub                                     # LangChainHub for prompt/templates\n",
    "!pip install -qU langchain-text-splitters                     # Text splitting\n",
    "\n",
    "# --- Miscellaneous ---\n",
    "!pip install jq                                               # JSON processor\n",
    "!pip install -U pydantic                                      # Data models/validation\n",
    "!pip install python-Levenshtein                               # Fuzzy string matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T14:06:16.093022Z",
     "iopub.status.busy": "2024-06-26T14:06:16.092706Z",
     "iopub.status.idle": "2024-06-26T14:06:34.872663Z",
     "shell.execute_reply": "2024-06-26T14:06:34.871741Z",
     "shell.execute_reply.started": "2024-06-26T14:06:16.092991Z"
    },
    "id": "sryXfdXH17Sf"
   },
   "outputs": [],
   "source": [
    "# --- Core Python & System Utilities ---\n",
    "import os\n",
    "from typing import Optional, Type, List, Union, Dict, Tuple, Set\n",
    "\n",
    "# --- PyTorch & Transformers (Huggingface) ---\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "# --- Huggingface PEFT (Parameter Efficient Fine-Tuning) ---\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "# --- Huggingface Datasets ---\n",
    "from datasets import load_dataset\n",
    "\n",
    "# --- LangChain: Core & Community Modules ---\n",
    "import pydantic\n",
    "\n",
    "# Text splitters and document handling\n",
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    RecursiveJsonSplitter\n",
    ")\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Vectorstores and Embeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "\n",
    "# LangChain Agents and Chains\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain import hub\n",
    "\n",
    "# LangChain advanced types (for tool/result parsing)\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQ1SJhtjhzjs"
   },
   "source": [
    "# meta-llama/Llama-3.2-3B-Instruct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTLKW6Nuh0VT"
   },
   "outputs": [],
   "source": [
    "def make_header(title, width=70):\n",
    "    pad = (width - len(title) - 2) // 2\n",
    "    line = \"# \" + \"-\" * width\n",
    "    center = f\"# {' ' * pad}{title}{' ' * pad}\" + (\"-\" if (len(title) % 2 == 0) else \" -\")\n",
    "    return f\"{line}\\n{center}\\n{line}\"\n",
    "\n",
    "print(make_header(\"Utility Functions for Fromatting Date, Ticket Sales, and Halls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T14:06:34.874771Z",
     "iopub.status.busy": "2024-06-26T14:06:34.873980Z",
     "iopub.status.idle": "2024-06-26T14:06:36.852640Z",
     "shell.execute_reply": "2024-06-26T14:06:36.851637Z",
     "shell.execute_reply.started": "2024-06-26T14:06:34.874735Z"
    },
    "id": "0S3gZVE917Sf"
   },
   "outputs": [],
   "source": [
    "# GET THE HF TOKEN\n",
    "from huggingface_hub import login\n",
    "login(token=user_secrets.get_secret(hf_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFiLkKPb17Sg"
   },
   "source": [
    "# Load quantized LLama 3.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T14:06:36.855400Z",
     "iopub.status.busy": "2024-06-26T14:06:36.855084Z",
     "iopub.status.idle": "2024-06-26T14:06:40.352602Z",
     "shell.execute_reply": "2024-06-26T14:06:40.351820Z",
     "shell.execute_reply.started": "2024-06-26T14:06:36.855371Z"
    },
    "id": "T13-oO9O17Sg",
    "outputId": "6382d587-29a0-4bb4-cf30-053e5f348f2c"
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "#                           Tokenizer Setup                            -\n",
    "# ----------------------------------------------------------------------\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "try:\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "  logger.info(\"Loaded tokenizer for {model_name}\")\n",
    "except Exception as e:\n",
    "  logger.error(\"Failed loading tokenizer for {model_name}\", exc_info=e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T14:06:40.353952Z",
     "iopub.status.busy": "2024-06-26T14:06:40.353664Z",
     "iopub.status.idle": "2024-06-26T14:06:40.358520Z",
     "shell.execute_reply": "2024-06-26T14:06:40.357690Z",
     "shell.execute_reply.started": "2024-06-26T14:06:40.353927Z"
    },
    "id": "I1XsTv8P17Sg"
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "#                  BitsAndBytes Quantization Settings                  -\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Enable 4-bit quantization to reduce memory usage and improve efficiency\n",
    "use_4bit = True\n",
    "\n",
    "# Computation data type used during inference\n",
    "bnb_4bit_compute_dtype = torch.bfloat16\n",
    "\n",
    "# Quantization type \"nf4\" (Normalized Float 4) generally offers better accuracy than \"fp4\"\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Disable nested quantization (double quantization), True only for extreme memory constraints\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T14:06:40.359787Z",
     "iopub.status.busy": "2024-06-26T14:06:40.359471Z",
     "iopub.status.idle": "2024-06-26T14:06:40.397199Z",
     "shell.execute_reply": "2024-06-26T14:06:40.396492Z",
     "shell.execute_reply.started": "2024-06-26T14:06:40.359758Z"
    },
    "id": "wS7awuxJ17Sh"
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "#          Initialize BitsAndBytes 4-bit Quantization Config           -\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=bnb_4bit_compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "a6758ee63c074156bde8b7eaa59240be",
      "58fdd4d30a564348bd1c4069de39ae9c",
      "9390949e3f7342b386c165eea4d15236",
      "e062ec6af90b4a808a536375f3df6e9c",
      "4756317093d846c0a882ef2fbd5cb0eb",
      "b320515a0f6b4ef981e5ddcea48e274e",
      "397b48a3e5014eb68ae3903e26c6ea37",
      "6178927dcff043df894c2d146d38b131",
      "776311f7331a4648915a53c3a2ea79ec",
      "0409603a721f4abd938999f1845d1a3c",
      "671a9e2d349344a49762667039bd0d7f",
      "960152c40cc241febdbeaa98b3893d34",
      "0855f978c0b840228d1820ec05f59ea3",
      "1464d99fd8f44145b5cab8ee6e123225",
      "da37e43e8b294a7d8dc64c9b700d6fe3",
      "bdcf5774e6434ba685d5ca208a7919d2",
      "17a391994b0e48bf87086ef020f4b41d",
      "84e142082d814a6a88d7dcb362872f8c",
      "7e7112fa300746cb898cf517a0e36d32",
      "598b1be5b98c4d4c83767b55f29a4fc5",
      "634f124d6f2b42b3bf9e13f726c18e00",
      "62bb42ce0ec747e1be7d739dd49ead3a"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T14:06:40.399040Z",
     "iopub.status.busy": "2024-06-26T14:06:40.398242Z",
     "iopub.status.idle": "2024-06-26T14:09:13.918933Z",
     "shell.execute_reply": "2024-06-26T14:09:13.918033Z",
     "shell.execute_reply.started": "2024-06-26T14:06:40.399016Z"
    },
    "id": "zjp2qEHb17Sh",
    "outputId": "7ba40903-33b4-4e71-c0aa-9f47048044a6"
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "#           Language Model: Quantized LLaMA 3.2 3B Instruct            -\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "try:\n",
    "  llama_model_original = AutoModelForCausalLM.from_pretrained(\n",
    "      model_name,\n",
    "      quantization_config=bnb_config,\n",
    "      device_map=\"cuda\"\n",
    "  )\n",
    "  logger.info(f\"Loaded model {model_name}\")\n",
    "except Exception as e:\n",
    "  logger.error(f\"Failed loading model {model_name}\")\n",
    "  raise\n",
    "\n",
    "\n",
    "print(f'Memory used by LLaMA model: {round(llama_model_original.get_memory_footprint()/1024/1024/1024, 2)} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnbcNiyd17Sh"
   },
   "source": [
    "# Count number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T14:09:13.920353Z",
     "iopub.status.busy": "2024-06-26T14:09:13.920056Z",
     "iopub.status.idle": "2024-06-26T14:09:13.928346Z",
     "shell.execute_reply": "2024-06-26T14:09:13.927485Z",
     "shell.execute_reply.started": "2024-06-26T14:09:13.920319Z"
    },
    "id": "jbkhhhfR17Sh",
    "outputId": "328222fc-fb01-4720-fad0-2d55a7f0e2a8"
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "#           Model Trainability Summary for Thea Chatbot App            -\n",
    "# ----------------------------------------------------------------------\n",
    "# This utility function calculates:\n",
    "# - Total number of model parameters\n",
    "# - Number of trainable (updatable) parameters\n",
    "# - Percentage of parameters that are trainable\n",
    "#\n",
    "# It helps verify whether the model is fully fine-tuned or partially tuned\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "\n",
    "    # Iterate over each parameter tensor in the model\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()  # count total parameters\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()  # count only trainable ones\n",
    "\n",
    "    # Return nicely formatted result\n",
    "    return f\"\"\"\n",
    "Trainability Report\n",
    "-----------------------\n",
    "Trainable parameters: {trainable_model_params:,}\n",
    "Total model parameters: {all_model_params:,}\n",
    "Trainable %: {100 * trainable_model_params / all_model_params:.2f}%\n",
    "\"\"\"\n",
    "\n",
    "# Call the function on your LLaMA model instance (change variable if needed)\n",
    "print(print_number_of_trainable_model_parameters(llama_model_original))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUWPbRxx17Si"
   },
   "source": [
    "# Build Custom Llama LLM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T15:37:02.439108Z",
     "iopub.status.busy": "2024-06-26T15:37:02.438220Z",
     "iopub.status.idle": "2024-06-26T15:37:02.456013Z",
     "shell.execute_reply": "2024-06-26T15:37:02.455110Z",
     "shell.execute_reply.started": "2024-06-26T15:37:02.439076Z"
    },
    "id": "Pp8lJW1Y17Si"
   },
   "outputs": [],
   "source": [
    "# --- Transformers: LLaMA model and tokenizer imports ---\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "from transformers.models.llama.tokenization_llama_fast import LlamaTokenizerFast\n",
    "from transformers.tokenization_utils_fast import PreTrainedTokenizerFast\n",
    "\n",
    "# --- LangChain: Base LLM and Callbacks ---\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "\n",
    "# --- LangChain: Prompt engineering and agent utilities ---\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain.memory import ConversationBufferWindowMemory, ConversationBufferMemory\n",
    "\n",
    "# --- Typing ---\n",
    "from typing import Optional, List, Mapping, Any\n",
    "\n",
    "# --- Custom LangChain-compatible wrapper for LLaMA ---\n",
    "class CustomLLMLLaMA(LLM):\n",
    "    model: LlamaForCausalLM\n",
    "    tokenizer: PreTrainedTokenizerFast\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None\n",
    "    ) -> str:\n",
    "        # Prepare messages in chat format as expected by the LLaMA model\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        encodeds = self.tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "        model_inputs = encodeds.to(self.model.device)\n",
    "\n",
    "        generated_ids = self.model.generate(\n",
    "            model_inputs,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=True,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "            top_k=4,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        decoded = self.tokenizer.batch_decode(generated_ids)\n",
    "        raw = decoded[0]\n",
    "\n",
    "        # Handle output extraction based on [INST] presence\n",
    "        if \"[/INST]\" in raw:\n",
    "            output = raw.split(\"[/INST]\", 1)[1].replace(\"</s>\", \"\").strip()\n",
    "        else:\n",
    "            output = raw.replace(\"</s>\", \"\").strip()\n",
    "\n",
    "        # Apply stop words, if any\n",
    "        if stop is not None:\n",
    "            for word in stop:\n",
    "                output = output.split(word)[0].strip()\n",
    "\n",
    "        # Pad with backticks if needed (for code block completion)\n",
    "        while not output.endswith(\"```\"):\n",
    "            output += \"`\"\n",
    "\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"model\": self.model}\n",
    "\n",
    "# --- Instantiate the wrapper with your model and tokenizer ---\n",
    "llama_model = CustomLLMLLaMA(model=llama_model_original, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T15:37:02.457888Z",
     "iopub.status.busy": "2024-06-26T15:37:02.457580Z",
     "iopub.status.idle": "2024-06-26T15:37:02.472507Z",
     "shell.execute_reply": "2024-06-26T15:37:02.471606Z",
     "shell.execute_reply.started": "2024-06-26T15:37:02.457852Z"
    },
    "id": "d0eNvE6117Si",
    "outputId": "68426f48-8870-4f56-9289-612fda1115a5"
   },
   "outputs": [],
   "source": [
    "print(llama_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:46.669373Z",
     "iopub.status.busy": "2024-06-26T16:51:46.668932Z",
     "iopub.status.idle": "2024-06-26T16:51:46.684288Z",
     "shell.execute_reply": "2024-06-26T16:51:46.683376Z",
     "shell.execute_reply.started": "2024-06-26T16:51:46.669327Z"
    },
    "id": "f7F8jBd417Si"
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "#    Utility Functions for Fromatting Date, Ticket Sales, and Stages   -\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "\n",
    "TIME_SUFFIX_RE = re.compile(r\"T00:00:00\")\n",
    "\n",
    "def strip_time_suffix(iso_date: str) -> str:\n",
    "    \"\"\"Removes the time component from ISO date strings (e.g. T00:00:00).\"\"\"\n",
    "    return TIME_SUFFIX_RE.sub('', iso_date)\n",
    "\n",
    "def ordinal_suffix(day: int) -> str:\n",
    "    \"\"\"Returns the appropriate ordinal suffix for a day (e.g. 1 → 'st').\"\"\"\n",
    "    if 11 <= day <= 13:\n",
    "        return 'th'\n",
    "    return {1: 'st', 2: 'nd', 3: 'rd'}.get(day % 10, 'th')\n",
    "\n",
    "def human_date(date_str: str, include_year: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Converts a date string (YYYY-MM-DD) to a readable English format.\n",
    "    e.g. '2024-04-16' → 'Tuesday 16th of April, 2024'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        suffix = ordinal_suffix(date.day)\n",
    "        day_str = f\"{date.strftime('%A')} {date.day}{suffix} of {date.strftime('%B')}\"\n",
    "        return f\"{day_str}, {date.year}\" if include_year else day_str\n",
    "    except ValueError:\n",
    "        return \"Invalid date\"\n",
    "\n",
    "def human_date_range(date_range: Tuple[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Formats a start/end ISO date pair to readable range.\n",
    "    e.g. ('2024-05-01T00:00:00', '2024-05-10T00:00:00')\n",
    "         → 'from Wednesday 1st of May to Friday 10th of May, 2024'\n",
    "    \"\"\"\n",
    "    start, end = map(strip_time_suffix, date_range)\n",
    "    return f\"from {human_date(start, include_year=False)} to {human_date(end, include_year=True)}\"\n",
    "\n",
    "\n",
    "def pluralize(word: str, count: int) -> str:\n",
    "    \"\"\"Adds 's' to a word if count is not 1.\"\"\"\n",
    "    return f\"{word}\" if count == 1 else f\"{word}s\"\n",
    "\n",
    "def tickets_sold_by_zone(\n",
    "    data: Dict[str, Dict[str, List[str]]],\n",
    "    zone: str = \"afternoon\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Returns number of tickets sold for a given time zone (e.g. 'afternoon').\n",
    "    \"\"\"\n",
    "    count = sum(len(slots.get(zone, [])) for slots in data.values())\n",
    "    return f\"{count} {pluralize('ticket', count)}\"\n",
    "\n",
    "def tickets_summary(data: Dict[str, Dict[str, List[str]]]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Returns a dictionary summarizing tickets sold per time slot.\n",
    "    Useful for assistant summaries or admin dashboards.\n",
    "    \"\"\"\n",
    "    zones = ['morning', 'afternoon', 'evening']\n",
    "    return {zone: tickets_sold_by_zone(data, zone) for zone in zones if any(slots.get(zone) for slots in data.values())}\n",
    "\n",
    "\n",
    "def stage_capacity(stage_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the seat capacity of a known stage.\n",
    "    Extend this as your venue expands.\n",
    "    \"\"\"\n",
    "    capacities = {\n",
    "        \"Stage A\": \"40 seats\",\n",
    "        \"Stage B\": \"46 seats\",\n",
    "    }\n",
    "    return capacities.get(stage_name, \"Capacity info not available\")\n",
    "\n",
    "\n",
    "def format_runtime(runtime_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts time formats like '1h 30min' to '1 hour and 30 minutes'.\n",
    "    Handles partial values (e.g. '45min').\n",
    "    \"\"\"\n",
    "    hours, minutes = 0, 0\n",
    "    for part in runtime_str.lower().split():\n",
    "        if 'h' in part:\n",
    "            hours = int(part.replace('h', '').strip())\n",
    "        elif 'min' in part:\n",
    "            minutes = int(part.replace('min', '').strip())\n",
    "\n",
    "    parts = []\n",
    "    if hours:\n",
    "        parts.append(f\"{hours} {pluralize('hour', hours)}\")\n",
    "    if minutes:\n",
    "        parts.append(f\"{minutes} {pluralize('minute', minutes)}\")\n",
    "\n",
    "    return \" and \".join(parts) if parts else \"Duration not specified\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Mock dataset for previewing functions\n",
    "    mock_data = {\n",
    "        \"2024-06-01\": {\n",
    "            \"morning\": [\"A1\"],\n",
    "            \"afternoon\": [\"B1\", \"B2\"],\n",
    "            \"evening\": []\n",
    "        },\n",
    "        \"2024-06-02\": {\n",
    "            \"afternoon\": [\"C1\", \"C2\", \"C3\"],\n",
    "            \"evening\": [\"D1\"]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:46.686718Z",
     "iopub.status.busy": "2024-06-26T16:51:46.686061Z",
     "iopub.status.idle": "2024-06-26T16:51:46.700699Z",
     "shell.execute_reply": "2024-06-26T16:51:46.699902Z",
     "shell.execute_reply.started": "2024-06-26T16:51:46.686684Z"
    },
    "id": "EPO1431A17Sj"
   },
   "outputs": [],
   "source": [
    "def generate_play_description(doc: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generate a rich, assistive natural language description for a theater play.\n",
    "    Designed for conversational delivery or accessibility-friendly UI display.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract core info\n",
    "    title = doc.get(\"title\", \"Unknown Title\")\n",
    "    playwriter = doc.get(\"playwriter\", \"Unknown Playwriter\")\n",
    "    headline = doc.get(\"headline\", \"\")\n",
    "    description = doc.get(\"description\", \"\")\n",
    "    genre = doc.get(\"genre\", \"Unknown Genre\")\n",
    "    runtime = format_runtime(doc.get(\"runtime\", \"Unknown\"))\n",
    "    cast = \", \".join(doc.get(\"cast\", []))\n",
    "    stage = doc.get(\"stage\", \"Unknown Stage\")\n",
    "    capacity = stage_capacity(stage)\n",
    "    age_limit = doc.get(\"ageLimit\", \"All Ages\")\n",
    "    additional_info = doc.get(\"additionalInfo\", \"No additional info available.\")\n",
    "    afternoon_time = doc.get(\"afternoon\", \"Unknown\")\n",
    "    night_time = doc.get(\"night\", \"Unknown\")\n",
    "    regular_price = doc.get(\"regularTickets\", {}).get(\"price\", \"?\")\n",
    "    special_price = doc.get(\"specialNeedsTickets\", {}).get(\"price\", \"?\")\n",
    "\n",
    "    # Format date range\n",
    "    available_dates = list(doc.get(\"availableDates\", {}).keys())\n",
    "    if len(available_dates) >= 2:\n",
    "        date_range_str = human_date_range((available_dates[0], available_dates[-1]))\n",
    "    else:\n",
    "        date_range_str = \"for a limited run\"\n",
    "\n",
    "    # Tickets sold info\n",
    "    afternoon_sold = tickets_sold_by_zone(doc['availableDates'], 'afternoon')\n",
    "    night_sold = tickets_sold_by_zone(doc['availableDates'], 'night')\n",
    "\n",
    "    # Age limit phrase\n",
    "    if age_limit == \"All Ages\":\n",
    "        age_phrase = \"suitable for all audience members.\"\n",
    "    else:\n",
    "        age_phrase = f\"recommended for ages {age_limit.replace('+', '')} and above.\"\n",
    "\n",
    "    # Construct description\n",
    "    return f\"\"\"\n",
    "**{title}** by *{playwriter}*\n",
    "*{headline}*\n",
    "\n",
    "{description}\n",
    "\n",
    "**Cast**: {cast}\n",
    "**Genre**: {genre}\n",
    "**Runtime**: {runtime}\n",
    "**Performances** take place {date_range_str}, with two daily showings:\n",
    "  • Afternoon at **{afternoon_time}**\n",
    "  • Evening at **{night_time}**\n",
    "\n",
    "**Venue**: {stage} — capacity: {capacity}\n",
    "  • Afternoon show: {afternoon_sold} sold\n",
    "  • Night show: {night_sold} sold\n",
    "\n",
    "**Tickets**:\n",
    "  • Regular: €{regular_price}\n",
    "  • Accessible: €{special_price}\n",
    "\n",
    "**Age suitability**: {age_phrase}\n",
    "**Additional Notes**: {additional_info}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUQ80xwPgsjP",
    "outputId": "fb02eec9-cd39-4d28-a179-e75614e217e0"
   },
   "outputs": [],
   "source": [
    "    print(\"Date Range Example:\")\n",
    "    print(human_date_range((\"2024-06-01T00:00:00\", \"2024-06-10T00:00:00\")))\n",
    "\n",
    "    print(\"\\nAfternoon Tickets Sold:\")\n",
    "    print(tickets_sold_by_zone(mock_data, \"afternoon\"))\n",
    "\n",
    "    print(\"\\nFull Ticket Summary:\")\n",
    "    print(tickets_summary(mock_data))\n",
    "\n",
    "    print(\"\\nStage A Info:\")\n",
    "    print(stage_capacity(\"Stage A\"))\n",
    "\n",
    "    print(\"\\nRuntime Formatter:\")\n",
    "    print(format_runtime(\"1h 15min\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:46.715909Z",
     "iopub.status.busy": "2024-06-26T16:51:46.715406Z",
     "iopub.status.idle": "2024-06-26T16:51:46.721532Z",
     "shell.execute_reply": "2024-06-26T16:51:46.720680Z",
     "shell.execute_reply.started": "2024-06-26T16:51:46.715886Z"
    },
    "id": "_QL-2qEK17Sj"
   },
   "outputs": [],
   "source": [
    "def safe_nested_get(d: dict, keys: list, default=None):\n",
    "    \"\"\"Safely traverse nested dicts with a list of keys.\"\"\"\n",
    "    value = d\n",
    "    try:\n",
    "        for k in keys:\n",
    "            value = value[k]\n",
    "        return value\n",
    "    except (KeyError, IndexError, TypeError):\n",
    "        return default\n",
    "\n",
    "def generate_play_metadata(play: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Generate structured metadata for a play: for RAG, vectorstore, UI cards, etc.\n",
    "    \"\"\"\n",
    "    # Date range: get first and last date\n",
    "    available_dates = list(play.get(\"availableDates\", {}).keys())\n",
    "    if available_dates:\n",
    "        start = strip_time_suffix(available_dates[0])[:10]\n",
    "        end = strip_time_suffix(available_dates[-1])[:10]\n",
    "        date_range = f\"{start} to {end}\"\n",
    "    else:\n",
    "        date_range = \"Date info unavailable\"\n",
    "\n",
    "    # Build metadata dictionary\n",
    "    metadata = {\n",
    "        \"source\": \"Thea\",\n",
    "        \"title\": play.get(\"title\", \"Unknown Title\"),\n",
    "        \"playwriter\": play.get(\"playwriter\", \"Unknown Playwriter\"),\n",
    "        \"genre\": play.get(\"genre\", \"Unknown Genre\"),\n",
    "        \"stage\": play.get(\"stage\", play.get(\"hall\", \"Unknown Stage\")),\n",
    "        \"date_range\": date_range,\n",
    "        \"age_limit\": play.get(\"ageLimit\", \"All Ages\"),\n",
    "        \"afternoon_time\": play.get(\"afternoon\", \"Not scheduled\"),\n",
    "        \"night_time\": play.get(\"night\", \"Not scheduled\"),\n",
    "        \"regular_price\": f\"{safe_nested_get(play, ['regularTickets', 'price'], '?')}€\",\n",
    "        \"special_price\": f\"{safe_nested_get(play, ['specialNeedsTickets', 'price'], '?')}€\",\n",
    "        \"cast_size\": len(play.get(\"cast\", [])),\n",
    "        \"cast\": \", \".join(play.get(\"cast\", [])),\n",
    "    }\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bn7gf2TNhMTL"
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def generate_play_descriptions_and_metadata(\n",
    "    json_data: List[Dict]\n",
    ") -> Tuple[List[str], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Transform a list of play dictionaries into:\n",
    "      • Rich natural language summaries (for chat, screen readers, etc.)\n",
    "      • Structured metadata dictionaries (for indexing, search, UI)\n",
    "\n",
    "    Args:\n",
    "        json_data: List of play dictionaries.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "          - documents: List of human-readable summaries for each play.\n",
    "          - metadata: List of structured metadata dicts.\n",
    "    \"\"\"\n",
    "    documents: List[str] = []\n",
    "    metadata: List[Dict] = []\n",
    "\n",
    "    for play in json_data:\n",
    "        play_description = generate_play_description(play)\n",
    "        play_metadata = generate_play_metadata(play)\n",
    "        documents.append(play_description)\n",
    "        metadata.append(play_metadata)\n",
    "\n",
    "    return documents, metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqwMsAJf17Sj"
   },
   "source": [
    "# Load and Tranform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:46.777441Z",
     "iopub.status.busy": "2024-06-26T16:51:46.777158Z",
     "iopub.status.idle": "2024-06-26T16:51:46.795390Z",
     "shell.execute_reply": "2024-06-26T16:51:46.794740Z",
     "shell.execute_reply.started": "2024-06-26T16:51:46.777416Z"
    },
    "id": "P4GKKasT17Sj"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "  # 1. Load\n",
    "  with open('/content/data/plays.json', 'r') as f:\n",
    "      data = json.load(f)\n",
    "\n",
    "  # 2. Generate summaries + metadata\n",
    "  summaries, metadata = generate_play_descriptions_and_metadata(data)\n",
    "\n",
    "  # 3. Build a quick lookup by title (lowercased for matching)\n",
    "  play_index = {\n",
    "      md['title'].lower(): {\n",
    "          'summary': doc,\n",
    "          'metadata': md\n",
    "      }\n",
    "      for doc, md in zip(summaries, metadata)\n",
    "  }\n",
    "  logger.info(\"Successfully read JSON\")\n",
    "except FileNotFoundError:\n",
    "  logger.error(\"JSON NOT FOUND\")\n",
    "except json.JSONDecodeError as e:\n",
    "  logger.error(\"Failed parsing JSON\", exc_info=e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:46.796883Z",
     "iopub.status.busy": "2024-06-26T16:51:46.796621Z",
     "iopub.status.idle": "2024-06-26T16:51:46.802196Z",
     "shell.execute_reply": "2024-06-26T16:51:46.801430Z",
     "shell.execute_reply.started": "2024-06-26T16:51:46.796860Z"
    },
    "id": "Nnz747U417Sj",
    "outputId": "2d9ff70c-ba7b-4fb2-bccc-2f772c948bbf"
   },
   "outputs": [],
   "source": [
    "# Generate documents and metadata\n",
    "info = generate_play_descriptions_and_metadata(data)\n",
    "documents = info[0]\n",
    "metadata = info[1]\n",
    "print(len(documents), len(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:46.913677Z",
     "iopub.status.busy": "2024-06-26T16:51:46.913405Z",
     "iopub.status.idle": "2024-06-26T16:51:46.922187Z",
     "shell.execute_reply": "2024-06-26T16:51:46.921351Z",
     "shell.execute_reply.started": "2024-06-26T16:51:46.913653Z"
    },
    "id": "KRvyhOQc17Sk",
    "outputId": "b5c4d85d-2b8c-4e49-978f-03ff8259707a"
   },
   "outputs": [],
   "source": [
    "def simple_chunk_text(text: str, chunk_size: int = 700) -> list:\n",
    "    \"\"\"\n",
    "    Splits a single text string into chunks of up to 'chunk_size' characters.\n",
    "    No overlap.\n",
    "    \"\"\"\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "chunks = []  # Holds all the chunks from all documents\n",
    "\n",
    "for doc in documents:\n",
    "    doc_chunks = simple_chunk_text(doc, chunk_size=700)\n",
    "    chunks.extend(doc_chunks)\n",
    "\n",
    "print(len(chunks))  # Total number of chunks produced\n",
    "print(chunks)       # List of chunk strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:46.983770Z",
     "iopub.status.busy": "2024-06-26T16:51:46.983273Z",
     "iopub.status.idle": "2024-06-26T16:51:46.987842Z",
     "shell.execute_reply": "2024-06-26T16:51:46.986950Z",
     "shell.execute_reply.started": "2024-06-26T16:51:46.983746Z"
    },
    "id": "qz-6BKVE17Sk",
    "outputId": "8c418456-110a-4770-9221-79b6be59c7d9"
   },
   "outputs": [],
   "source": [
    "print(chunks[0] + chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:47.041953Z",
     "iopub.status.busy": "2024-06-26T16:51:47.041188Z",
     "iopub.status.idle": "2024-06-26T16:51:47.046588Z",
     "shell.execute_reply": "2024-06-26T16:51:47.045706Z",
     "shell.execute_reply.started": "2024-06-26T16:51:47.041927Z"
    },
    "id": "-2F7zxbP17Sk",
    "outputId": "96d0d330-5f48-4465-88a8-e79b8c5e9400"
   },
   "outputs": [],
   "source": [
    "def extract_titles_from_metadata(metadata_list):\n",
    "    \"\"\"Extracts all titles from a list of metadata dictionaries.\"\"\"\n",
    "    return [md.get('title', 'Unknown Title') for md in metadata_list]\n",
    "\n",
    "titles = extract_titles_from_metadata(metadata)\n",
    "print(titles, len(titles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:47.048834Z",
     "iopub.status.busy": "2024-06-26T16:51:47.048430Z",
     "iopub.status.idle": "2024-06-26T16:51:47.056990Z",
     "shell.execute_reply": "2024-06-26T16:51:47.056137Z",
     "shell.execute_reply.started": "2024-06-26T16:51:47.048801Z"
    },
    "id": "rN7MeNZD17Sk",
    "outputId": "b0b2bbeb-2e02-477c-c7af-2e38f40c6c00"
   },
   "outputs": [],
   "source": [
    "# Install fuzzywuzzy if needed\n",
    "!pip install fuzzywuzzy\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def find_play_titles(text, titles=titles, threshold=70):\n",
    "    \"\"\"\n",
    "    Find titles in the user's text using fuzzy matching and substring checks.\n",
    "\n",
    "    Args:\n",
    "        text (str): User input text.\n",
    "        titles (list): List of known play titles.\n",
    "        threshold (int): Fuzzy match score threshold (0-100).\n",
    "\n",
    "    Returns:\n",
    "        List of matching titles (may be empty).\n",
    "    \"\"\"\n",
    "    found_titles = []\n",
    "    text_lower = text.lower()  # Normalize case\n",
    "\n",
    "    for title in titles:\n",
    "        title_lower = title.lower()\n",
    "        # Check for direct substring match\n",
    "        if title_lower in text_lower:\n",
    "            found_titles.append(title)\n",
    "        else:\n",
    "            # Check fuzzy match for each word in the input text\n",
    "            for word in text_lower.split():\n",
    "                ratio = fuzz.ratio(word, title_lower)\n",
    "                if ratio >= threshold:\n",
    "                    found_titles.append(title)\n",
    "                    break  # Only add the same title once\n",
    "\n",
    "    return found_titles\n",
    "\n",
    "# Example usage:\n",
    "# user_input = \"I want info about Hamlet\"\n",
    "# print(find_play_titles(user_input, titles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:47.058617Z",
     "iopub.status.busy": "2024-06-26T16:51:47.058294Z",
     "iopub.status.idle": "2024-06-26T16:51:47.070276Z",
     "shell.execute_reply": "2024-06-26T16:51:47.069572Z",
     "shell.execute_reply.started": "2024-06-26T16:51:47.058593Z"
    },
    "id": "gqVbrjwY17Sk",
    "outputId": "4b372453-2592-4c57-d45d-1b771ca58d35"
   },
   "outputs": [],
   "source": [
    "for i in range (0, len(metadata)+5, 2):\n",
    "  metadata.insert(i+1, metadata[i])\n",
    "print(len(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:47.085129Z",
     "iopub.status.busy": "2024-06-26T16:51:47.084895Z",
     "iopub.status.idle": "2024-06-26T16:51:47.091030Z",
     "shell.execute_reply": "2024-06-26T16:51:47.090207Z",
     "shell.execute_reply.started": "2024-06-26T16:51:47.085108Z"
    },
    "id": "Q3npy8lM17Sk"
   },
   "outputs": [],
   "source": [
    "def custom_sort_documents(id_list, document_list):\n",
    "    \"\"\"\n",
    "    Sorts document chunks based on their ID (e.g., 'id1a', 'id1b').\n",
    "    Orders by numeric ID first, then suffix alphabetically.\n",
    "    Returns a list of documents in sorted order.\n",
    "    \"\"\"\n",
    "    # Dynamically build base_order based on unique bases in id_list\n",
    "    unique_bases = sorted({id[:-1] for id in id_list})\n",
    "    base_order = {base: i for i, base in enumerate(unique_bases)}\n",
    "\n",
    "    # Custom sort: by base order, then by suffix (alphabetical)\n",
    "    def sort_key(item):\n",
    "        doc_id = item[0]\n",
    "        base = doc_id[:-1]\n",
    "        suffix = doc_id[-1]\n",
    "        return (base_order.get(base, 0), suffix)\n",
    "\n",
    "    # Zip, sort, unzip\n",
    "    sorted_items = sorted(zip(id_list, document_list), key=sort_key)\n",
    "    # If sorted_items is empty, zip(*) fails. Handle that:\n",
    "    if not sorted_items:\n",
    "        return []\n",
    "\n",
    "    sorted_ids, sorted_documents = zip(*sorted_items)\n",
    "    return list(sorted_documents)\n",
    "\n",
    "# Example usage:\n",
    "# ids = ['id2b', 'id1a', 'id1b', 'id2a']\n",
    "# docs = ['D', 'A', 'B', 'C']\n",
    "# print(custom_sort_documents(ids, docs))  # Output: ['A', 'B', 'C', 'D']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9N_uMGd17Sk"
   },
   "source": [
    "# Set Up Chroma Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:47.114228Z",
     "iopub.status.busy": "2024-06-26T16:51:47.113985Z",
     "iopub.status.idle": "2024-06-26T16:51:47.121903Z",
     "shell.execute_reply": "2024-06-26T16:51:47.121021Z",
     "shell.execute_reply.started": "2024-06-26T16:51:47.114207Z"
    },
    "id": "YIeropSc17Sk"
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:47.183560Z",
     "iopub.status.busy": "2024-06-26T16:51:47.183085Z",
     "iopub.status.idle": "2024-06-26T16:51:47.193615Z",
     "shell.execute_reply": "2024-06-26T16:51:47.192742Z",
     "shell.execute_reply.started": "2024-06-26T16:51:47.183534Z"
    },
    "id": "ADg6N6no17Sl"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if plays_collection:\n",
    "        try:\n",
    "            chroma_client.delete_collection(name=\"plays\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not delete collection 'plays'. Reason: {e}\")\n",
    "        try:\n",
    "            del plays_collection\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not delete variable 'plays_collection'. Reason: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"General error while handling plays_collection: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:47.195253Z",
     "iopub.status.busy": "2024-06-26T16:51:47.194986Z",
     "iopub.status.idle": "2024-06-26T16:51:47.569925Z",
     "shell.execute_reply": "2024-06-26T16:51:47.568991Z",
     "shell.execute_reply.started": "2024-06-26T16:51:47.195230Z"
    },
    "id": "u5jnroW717Sl",
    "outputId": "dc6e41c1-d331-490a-93a1-3f3603a13ec7"
   },
   "outputs": [],
   "source": [
    "# Using default embedding model: 'all-MiniLM-L6-v2'\n",
    "plays_collection = chroma_client.create_collection(name=\"plays\")\n",
    "\n",
    "plays_collection.add(\n",
    "    documents = chunks,\n",
    "    metadatas = metadata,\n",
    "    ids = [\"id1a\", \"id1b\", \"id2a\", \"id2b\", \"id3a\", \"id3b\", \"id4a\", \"id4b\", \"id5a\", \"id5b\", \"id6a\", \"id6b\"]\n",
    ")\n",
    "\n",
    "plays_collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1K-1Ake517Sl"
   },
   "source": [
    "# Funntion Calling - Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:47.572230Z",
     "iopub.status.busy": "2024-06-26T16:51:47.571736Z",
     "iopub.status.idle": "2024-06-26T16:51:47.579098Z",
     "shell.execute_reply": "2024-06-26T16:51:47.578323Z",
     "shell.execute_reply.started": "2024-06-26T16:51:47.572147Z"
    },
    "id": "YtccOyG217Sl"
   },
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from pydantic import ValidationError\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "from typing import Optional, Type\n",
    "\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T16:51:47.580540Z",
     "iopub.status.busy": "2024-06-26T16:51:47.580196Z",
     "iopub.status.idle": "2024-06-26T16:51:47.587758Z",
     "shell.execute_reply": "2024-06-26T16:51:47.586963Z",
     "shell.execute_reply.started": "2024-06-26T16:51:47.580507Z"
    },
    "id": "y1rLRWwc17Sl"
   },
   "outputs": [],
   "source": [
    "inputs={'input': \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.632378Z",
     "iopub.status.busy": "2024-06-26T20:12:35.632060Z",
     "iopub.status.idle": "2024-06-26T20:12:35.648263Z",
     "shell.execute_reply": "2024-06-26T20:12:35.647440Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.632349Z"
    },
    "id": "EJMQqjkh17Sl"
   },
   "outputs": [],
   "source": [
    "class GetPlayInformation(BaseTool):\n",
    "    name: str = \"getPlayInformation\"\n",
    "    description: str = (\n",
    "        \"The user wants information about a play or wants to ask a general question regarding the details of a play \"\n",
    "        \"(such as ticket costs, age limit, ticket availability, etc.).\"\n",
    "    )\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Finds all the relevant info to the user's prompt.\"\"\"\n",
    "        query = inputs.get('input', '')\n",
    "        print(f\"Received input: {query}\")\n",
    "\n",
    "        try:\n",
    "            print(\"INSIDE GetPlayInformation TOOL:\")\n",
    "\n",
    "            # Attempt to identify the play(s) mentioned (catch misspellings)\n",
    "            playFound = find_play_titles(query)  # List of close matches\n",
    "            print(f\"Plays found: {playFound}\")\n",
    "\n",
    "            # Query ChromaDB/collection using the play title if found\n",
    "            if playFound:\n",
    "                # Use the play title for more relevant results\n",
    "                retrieved_plays_info = plays_collection.query(\n",
    "                    query_texts=[query],\n",
    "                    n_results=2,\n",
    "                    where={\"title\": str(playFound[0])}\n",
    "                )\n",
    "            else:\n",
    "                # No specific play found; search more broadly\n",
    "                retrieved_plays_info = plays_collection.query(\n",
    "                    query_texts=[query],\n",
    "                    n_results=8\n",
    "                )\n",
    "\n",
    "            # Extract and sort documents if results exist\n",
    "            if retrieved_plays_info and len(retrieved_plays_info['documents']) > 0:\n",
    "                retrieved_documents_sorted = custom_sort_documents(\n",
    "                    retrieved_plays_info['ids'][0],\n",
    "                    retrieved_plays_info['documents'][0]\n",
    "                )\n",
    "                print(f\"Retrieved and sorted {len(retrieved_documents_sorted)} documents.\")\n",
    "                context = \"\\n\\n\".join(retrieved_documents_sorted)\n",
    "            else:\n",
    "                context = \"\"\n",
    "\n",
    "            # Build response with navigation info if a play was recognized\n",
    "            if playFound:\n",
    "                return (\n",
    "                    \"USER_WANTS_TO_GET_PLAY_INFO-\" + playFound[0]\n",
    "                    + \"=> \" + context\n",
    "                )\n",
    "\n",
    "            # Otherwise, just return the context without a play\n",
    "            return (\n",
    "                \"USER_WANTS_TO_GET_PLAY_INFO=> \" + context\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Exception during execution of 'GetPlayInformation' tool: {str(e)}\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "\n",
    "\n",
    "get_play_info = GetPlayInformation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.649659Z",
     "iopub.status.busy": "2024-06-26T20:12:35.649370Z",
     "iopub.status.idle": "2024-06-26T20:12:35.669655Z",
     "shell.execute_reply": "2024-06-26T20:12:35.668943Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.649636Z"
    },
    "id": "hGLSeXvS17Sl"
   },
   "outputs": [],
   "source": [
    "class PlayChooser(BaseTool):\n",
    "    name: str = \"choosePlay\"\n",
    "    description: str = \"The user wants to choose a play to book a ticket for.\"\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        play_query = inputs.get('input', '')\n",
    "        try:\n",
    "            # Attempt to find close-matching play titles (robust to typos)\n",
    "            play_found = find_play_titles(play_query)\n",
    "\n",
    "            # If no play is found, prompt user with available titles\n",
    "            if not play_found:\n",
    "                available = \", \".join(titles)\n",
    "                return (\n",
    "                    \"USER_CHOSE_INVALID_PLAY=> \"\n",
    "                    \"Sorry, I couldn't find that play. Please provide a valid play title. \"\n",
    "                    f\"Currently available plays: {available}.\"\n",
    "                )\n",
    "\n",
    "            # If found, confirm selection and prompt for next booking slot(s)\n",
    "            play_title = play_found[0]\n",
    "            return (\n",
    "                f\"USER_CHOSE_THE_PLAY-{play_title}=> \"\n",
    "                f\"You selected **{play_title}**.\\n\"\n",
    "                \"I can't directly book a ticket for you due to Thea's theater policy. \\n\\nBy pressing the button below, I can redirect you to the screen for booking a ticket.\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch any unexpected errors for robust operation\n",
    "            return f\"Exception during execution of 'PlayChooser' tool: {str(e)}\"\n",
    "\n",
    "choose_play = PlayChooser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.698547Z",
     "iopub.status.busy": "2024-06-26T20:12:35.697949Z",
     "iopub.status.idle": "2024-06-26T20:12:35.713685Z",
     "shell.execute_reply": "2024-06-26T20:12:35.712973Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.698522Z"
    },
    "id": "vn_R_SWf17Sm"
   },
   "outputs": [],
   "source": [
    "class HumanContact(BaseTool):\n",
    "    name: str = \"contactHuman\"\n",
    "    description: str = (\n",
    "        \"Doesn't take arguments. The user wants to contact a human at Thea. \"\n",
    "        \"Provide the official contact details—phone number, website, Instagram—and encourage the user to reach out via their preferred method. \"\n",
    "        \"Use a warm, polite, and professional tone. Do NOT make up any information.\"\n",
    "    )\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        # No arguments for this tool\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        Respond to the user with official, up-to-date contact options for Thea's human support.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"INSIDE HUMAN CONTACT TOOL\")\n",
    "            return (\n",
    "                \"USER_WANTS_TO_CONTACT_A_HUMAN=> \"\n",
    "                \"If you would like to speak with a member of our team, you can contact Thea directly by phone at +30 210 123 4567, \"\n",
    "                \"visit our website at https://www.thea.com, or reach out via Instagram at https://www.instagram.com/thea. \"\n",
    "                \"We're always happy to help—please choose whichever method is most convenient for you!\"\n",
    "                \"\\n\\n\"\n",
    "                \"By pressing the button below, I can redirect you to the screen for contacting a human employee of Thea.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Exception during execution of \\\"HumanContact\\\" tool: {e}\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"This tool does not support async.\")\n",
    "\n",
    "# Instantiate\n",
    "contact_human = HumanContact()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.714980Z",
     "iopub.status.busy": "2024-06-26T20:12:35.714707Z",
     "iopub.status.idle": "2024-06-26T20:12:35.730281Z",
     "shell.execute_reply": "2024-06-26T20:12:35.729548Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.714956Z"
    },
    "id": "VSBiaEct17Sm"
   },
   "outputs": [],
   "source": [
    "class GetDirections(BaseTool):\n",
    "    name: str = \"getTheaterDirections\"\n",
    "    description: str = (\n",
    "        \"Doesn't take arguments. The user wants to know how to get to Thea or the official location. \"\n",
    "        \"Respond with the official address, coordinates (LatLng), postal code, nearby landmarks, and provide contact info.\"\n",
    "    )\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        Provide official address, coordinates, postal code, and nearby landmark information for Thea Theater in Athens.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"INSIDE GET DIRECTIONS TOOL:\")\n",
    "            return (\n",
    "                \"USER_WANTS_TO_GET_DIRECTIONS=> \"\n",
    "                \"Thea Theater is located in central Athens, Greece, near Omonia Square (Plateia Omonias), which is a major commercial and transportation hub. \"\n",
    "                \"Our official coordinates are **37.9838° N, 23.7275° E** (postal code: 10551). \"\n",
    "                \"Nearby streets include Pireos Street and Stoa Lykourgou, making Thea easy to reach by metro or bus.\\n\\n\"\n",
    "                \"For directions or map, please visit our website: https://www.thea.com\\n\"\n",
    "                \"You can also contact us by phone at +30 210 123 4567 or via Instagram at https://www.instagram.com/thea.\\n\"\n",
    "                \"If you need specific travel advice or accessibility information, just let us know!\"\n",
    "                \"\\n\\n\"\n",
    "                \"By pressing the button below, I can redirect you to the screen for getting directions to Thea Theater.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Exception during execution of \\\"GetDirections\\\" tool: {e}\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"This tool does not support async.\")\n",
    "\n",
    "get_directions = GetDirections()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.732057Z",
     "iopub.status.busy": "2024-06-26T20:12:35.731419Z",
     "iopub.status.idle": "2024-06-26T20:12:35.743694Z",
     "shell.execute_reply": "2024-06-26T20:12:35.742952Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.732024Z"
    },
    "id": "7liczzob17Sm"
   },
   "outputs": [],
   "source": [
    "class GetTheaterInformation(BaseTool):\n",
    "    name: str = \"getTheaterInformation\"\n",
    "    description: str = (\n",
    "        \"Doesn't take arguments. The user wants to learn more about Thea theater, either general or specific information.\"\n",
    "    )\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        # No arguments expected for this tool\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        Provide general or specific information about Thea Theater.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"INSIDE GET THEATER INFORMATION TOOL\")\n",
    "            return (\n",
    "                \"USER_WANTS_TO_GET_THEATER_INFO=> \"\n",
    "                \"Thea is a modern theater located in the heart of Athens, Greece, near Omonia Square (LatLng: 37.9838° N, 23.7275° E). \"\n",
    "                \"We feature two stages—Stage A and Stage B—each hosting a different play every day, with both afternoon and evening performances. \"\n",
    "                \"Thea is fully wheelchair accessible, and select shows offer sign language interpreters and supertitles for the hearing impaired. \"\n",
    "                \"Tickets can be purchased online (https://www.thea.com), through our mobile app, or directly at the counter. \"\n",
    "                \"For more details about our facilities, current program, accessibility, or anything else, please ask! \"\n",
    "                \"You can also visit our website at https://www.thea.com or call us at +30 210 123 4567.\"\n",
    "                \"\\n\\n\"\n",
    "                \"By pressing the button below, I can redirect you to the screen for getting more information about Thea Theater.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Exception during execution of \\\"GetTheaterInformation\\\" tool: {e}\"\n",
    "\n",
    "# Instantiate for use\n",
    "get_theater_info = GetTheaterInformation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.745027Z",
     "iopub.status.busy": "2024-06-26T20:12:35.744715Z",
     "iopub.status.idle": "2024-06-26T20:12:35.761274Z",
     "shell.execute_reply": "2024-06-26T20:12:35.760535Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.744994Z"
    },
    "id": "3lC-aKIA17Sn"
   },
   "outputs": [],
   "source": [
    "class ComplaintMaker(BaseTool):\n",
    "    name: str = \"makeComplaint\"\n",
    "    description: str = (\n",
    "        \"Doesn't take arguments. The user wants to make a complaint about the theater. \"\n",
    "        \"Apologize for the inconvenience and just say that they can fill out a complaint submission form.\"\n",
    "    )\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        # No arguments for this tool\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        Respond to a user who wants to make a complaint about the theater.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"INSIDE COMPLAINT MAKER TOOL: \")\n",
    "            return (\n",
    "                \"USER_WANTS_TO_SUBMIT_A_COMPLAINT=> \"\n",
    "                \"We sincerely apologize for any inconvenience you have experienced at Thea. \"\n",
    "                \"You may submit a complaint using the form available in our app, and our team will review your feedback as soon as possible. \"\n",
    "                \"If you need any assistance or would prefer to speak to someone, please contact us directly at +30 210 123 4567 or via our website at https://www.thea.com. \"\n",
    "                \"Thank you for helping us improve your theater experience.\"\n",
    "                \"\\n\\n\"\n",
    "                \"By pressing the button below, I can redirect you to the screen for making a complaint.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Exception during execution of \\\"ComplaintMaker\\\" tool: {e}\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"This tool does not support async.\")\n",
    "\n",
    "# Instantiate for use\n",
    "make_complaint = ComplaintMaker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.764829Z",
     "iopub.status.busy": "2024-06-26T20:12:35.764546Z",
     "iopub.status.idle": "2024-06-26T20:12:35.778126Z",
     "shell.execute_reply": "2024-06-26T20:12:35.777437Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.764806Z"
    },
    "id": "eCVtHF5X17Sn"
   },
   "outputs": [],
   "source": [
    "class TicketCanceler(BaseTool):\n",
    "    name: str = \"cancelTicket\"\n",
    "    description: str = (\n",
    "        \"Doesn't take arguments. The user wants or needs to cancel their booking/ticket for a play(s) they have booked. \"\n",
    "        \"Respond by saying that it is a shame they won't be able to come to the play and tell them that you will redirect them to the appropriate screen so they can cancel their e-ticket.\"\n",
    "    )\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        # No arguments for this tool\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        Respond when a user wants to cancel their booking/ticket.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"INSIDE TICKET CANCELER TOOL\")\n",
    "            return (\n",
    "                \"USER_CANCELS_TICKET=> \"\n",
    "                \"We're sorry you won't be able to attend your selected performance at Thea. \"\n",
    "                \"Your ticket was successfully deleted.\"\n",
    "                \"If you need any help with the cancellation process, please contact us at +30 210 123 4567 or visit https://www.thea.com for assistance.\"\n",
    "                \"\\n\\n\"\n",
    "                \"By pressing the button below, I can redirect you to the screen for canceling your ticket.\"\n",
    "\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Exception during execution of \\\"TicketCanceler\\\" tool: {e}\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"This tool does not support async.\")\n",
    "\n",
    "# Instantiate for use\n",
    "cancel_ticket = TicketCanceler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.779514Z",
     "iopub.status.busy": "2024-06-26T20:12:35.779176Z",
     "iopub.status.idle": "2024-06-26T20:12:35.795030Z",
     "shell.execute_reply": "2024-06-26T20:12:35.794347Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.779484Z"
    },
    "id": "vMJTv4ID17Sn"
   },
   "outputs": [],
   "source": [
    "class ShowPurchasedTickets(BaseTool):\n",
    "    name: str = \"showTickets\"\n",
    "    description: str = (\n",
    "        \"Doesn't take arguments. The user wants to see all their purchased/booked tickets. \"\n",
    "        \"Respond by telling them that you will redirect them to the 'My e-Tickets' screen, where they can view, cancel, or download their e-tickets.\"\n",
    "    )\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        # No arguments for this tool\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        Respond to a user who wants to view their purchased tickets.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"INSIDE SHOW PURCHASED TICKETS TOOL\")\n",
    "            return (\n",
    "                \"USER_SEES_PURCHASED_TICKETS=> \"\n",
    "                \"You can view all of your booked tickets in the 'My e-Tickets' section of the app. \"\n",
    "                \"From there, you can also cancel or download your tickets as needed. \"\n",
    "                \"Would you like to go to the 'My e-Tickets' screen now?\"\n",
    "                \"\\n\\n\"\n",
    "                \"By pressing the button below, I can redirect you to My e-Tickets' screen to see your tickets.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Exception during execution of \\\"ShowPurchasedTickets\\\" tool: {e}\"\n",
    "\n",
    "show_purchased_tickets = ShowPurchasedTickets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.796391Z",
     "iopub.status.busy": "2024-06-26T20:12:35.796042Z",
     "iopub.status.idle": "2024-06-26T20:12:35.808983Z",
     "shell.execute_reply": "2024-06-26T20:12:35.808234Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.796360Z"
    },
    "id": "LTbTHqNd17Sn"
   },
   "outputs": [],
   "source": [
    "class CannotUnderstand(BaseTool):\n",
    "    \"\"\"\n",
    "    Tool for handling user input that is gibberish, incoherent, or in an unsupported language.\n",
    "    Politely informs the user and prompts them to try again.\n",
    "    \"\"\"\n",
    "    name: str = \"cannotUnderstand\"\n",
    "    description: str = (\n",
    "        \"Doesn't take arguments. The user input is gibberish, incoherent, or in a language other than English. \"\n",
    "        \"Say that you cannot understand, and prompt the user to try again.\"\n",
    "    )\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        # No arguments for this tool\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        Respond when user input is not understandable.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"INSIDE CANNOT UNDERSTAND TOOL\")\n",
    "            return (\n",
    "                \"USER_INPUT_NOT_UNDERSTANDABLE=> \"\n",
    "                \"I'm sorry, but I didn't understand your message. Could you please rephrase or try again?\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Exception during execution of \\\"CannotUnderstand\\\" tool: {e}\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"This tool does not support async.\")\n",
    "\n",
    "# Instantiate for use\n",
    "cannot_understand = CannotUnderstand()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.810341Z",
     "iopub.status.busy": "2024-06-26T20:12:35.810031Z",
     "iopub.status.idle": "2024-06-26T20:12:35.826706Z",
     "shell.execute_reply": "2024-06-26T20:12:35.825921Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.810266Z"
    },
    "id": "DLD77h4s17Sn"
   },
   "outputs": [],
   "source": [
    "class UnrelatedInput(BaseTool):\n",
    "    \"\"\"\n",
    "    Tool for handling input unrelated to the Thea theater.\n",
    "    Politely informs the user about the assistant's domain.\n",
    "    \"\"\"\n",
    "    name: str = \"unrelatedInput\"\n",
    "    description: str = (\n",
    "        \"Doesn't take arguments. The user said something not related to Thea theater in any way. \"\n",
    "        \"Inform the user that only questions related to Thea (such as plays, ticket booking or cancellation, etc.) can be answered.\"\n",
    "    )\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        # No arguments for this tool\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        Respond when the user's input is unrelated to the theater.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"INSIDE UNRELATED INPUT TOOL\")\n",
    "            return (\n",
    "                \"USER_INPUT_UNRELATED_TO_THEATER=> \"\n",
    "                \"I'm here to help with questions related to Thea theater, such as information about our plays, ticket booking or cancellation, directions, and other theater-related topics. \"\n",
    "                \"Please ask something related to Thea so I can assist you!\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Exception during execution of \\\"UnrelatedInput\\\" tool: {e}\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"This tool does not support async.\")\n",
    "\n",
    "# Instantiate for use\n",
    "unrelated_input = UnrelatedInput()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.838047Z",
     "iopub.status.busy": "2024-06-26T20:12:35.837794Z",
     "iopub.status.idle": "2024-06-26T20:12:35.853782Z",
     "shell.execute_reply": "2024-06-26T20:12:35.852964Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.838025Z"
    },
    "id": "49srm5SY17Sn"
   },
   "outputs": [],
   "source": [
    "class Other(BaseTool):\n",
    "    name: str = \"other\"\n",
    "    description: str = (\n",
    "        \"Doesn't take arguments. Use this tool if none of the others are a good fit. \"\n",
    "        \"Don't hesitate to use this tool!\"\n",
    "    )\n",
    "\n",
    "    def _to_args_and_kwargs(self, *args, **kwargs):\n",
    "        # No arguments for this tool\n",
    "        return (), {}\n",
    "\n",
    "    def _run(self, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"\n",
    "        Default fallback when no other tool is appropriate.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"INSIDE TOOL OTHER\")\n",
    "            return (\n",
    "                \"OTHER=>This question doesn't match any specific category, but I'm here to help! \"\n",
    "                \"Please clarify your request or let me know how I can assist you further.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Exception during execution of \\\"Other\\\" tool: {e}\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"This tool does not support async.\")\n",
    "\n",
    "# Instantiate the tool\n",
    "other = Other()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.855475Z",
     "iopub.status.busy": "2024-06-26T20:12:35.854942Z",
     "iopub.status.idle": "2024-06-26T20:12:35.862105Z",
     "shell.execute_reply": "2024-06-26T20:12:35.861341Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.855450Z"
    },
    "id": "fR0-A0Ml17Sn"
   },
   "outputs": [],
   "source": [
    "tools = [cannot_understand, unrelated_input, choose_play, make_complaint, contact_human, get_directions, cancel_ticket, show_purchased_tickets, get_theater_info, get_play_info, other]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSUMd9Ov17Sn"
   },
   "source": [
    "# Create Prompts and Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.863427Z",
     "iopub.status.busy": "2024-06-26T20:12:35.863173Z",
     "iopub.status.idle": "2024-06-26T20:12:35.871177Z",
     "shell.execute_reply": "2024-06-26T20:12:35.870459Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.863404Z"
    },
    "id": "oSIbeGN317So"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import render_text_description_and_args, render_text_description\n",
    "from langchain.memory import ConversationBufferWindowMemory,ConversationBufferMemory\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.872581Z",
     "iopub.status.busy": "2024-06-26T20:12:35.872240Z",
     "iopub.status.idle": "2024-06-26T20:12:35.883921Z",
     "shell.execute_reply": "2024-06-26T20:12:35.883050Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.872551Z"
    },
    "id": "Dcwxwh2I17So"
   },
   "outputs": [],
   "source": [
    "# Instantiate ConversationBufferMemory\n",
    "memory = ConversationBufferWindowMemory(\n",
    " memory_key='chat_history', return_messages=True, k=4\n",
    ")\n",
    "\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.885276Z",
     "iopub.status.busy": "2024-06-26T20:12:35.885013Z",
     "iopub.status.idle": "2024-06-26T20:12:35.912132Z",
     "shell.execute_reply": "2024-06-26T20:12:35.911213Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.885248Z"
    },
    "id": "wNweIR-K17So",
    "outputId": "f957bd04-da22-4616-8cc3-e90bfebc3947"
   },
   "outputs": [],
   "source": [
    "rendered_tools = render_text_description(tools)\n",
    "print(render_text_description_and_args(tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.913528Z",
     "iopub.status.busy": "2024-06-26T20:12:35.913226Z",
     "iopub.status.idle": "2024-06-26T20:12:35.921150Z",
     "shell.execute_reply": "2024-06-26T20:12:35.920211Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.913496Z"
    },
    "id": "b8Oqw6eW17So",
    "outputId": "d2feb090-413c-4f7f-dcff-d0178f54d752"
   },
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are a **polite, warm, and professional AI assistant** for Thea, a theater in Athens, Greece.\n",
    "\n",
    "**Thea - Information:**\n",
    "- **Location:** Omonia StreetAthens, Greece (LatLng: 37.9838, 23.7275)\n",
    "- **Website:** https://www.thea.com\n",
    "- **Phone:** +30 210 123 4567\n",
    "- **Instagram:** https://www.instagram.com/thea\n",
    "\n",
    "**Hours of Operation:**\n",
    "- Monday to Friday: 10:00 – 24:00\n",
    "- Saturday & Sunday: 15:00 – 24:00\n",
    "\n",
    "**Ticketing:** Tickets can be purchased online (https://www.thea.com), through the app, or at the counter desk.\n",
    "\n",
    "**Accessibility:** The theater has a wheelchair accessible entrance and seating.\n",
    "\n",
    "**Common User Queries:**\n",
    "- \"What's playing this weekend?\"\n",
    "- \"How can I buy tickets?\"\n",
    "- \"How can I cancel my ticket?\" or \"I want a refund for my ticket\"\n",
    "- \"Where is the theatre located?\"\n",
    "- \"What hours does the theatre work?\"\n",
    "\n",
    "**Important Response Guidelines:**\n",
    "- Always use a warm, polite, professional, and informative tone.\n",
    "- Only cite information you have (do **not** make up or \"hallucinate\" answers).\n",
    "- If you do not know the answer, apologize and politely redirect or suggest the user contact the theater.\n",
    "- Always provide exact URLs (e.g., https://www.thea.com) and phone numbers (+30 210 123 4567) when requested or relevant.\n",
    "- Never include information that is not explicitly provided here.\n",
    "\n",
    "**You have access to the following set of tools. Here are the tool names and descriptions:**\n",
    "{rendered_tools}\n",
    "\n",
    "**Instructions:**\n",
    "- Given the user’s input, choose the tool that best fits their request.\n",
    "- Return your answer strictly as a JSON object with **'name'** and **'arguments'** keys.\n",
    "- The **arguments** value should be a dictionary, with argument names as keys and their values filled in appropriately.\n",
    "- **Do not provide explanations or any text outside the JSON.**\n",
    "\"\"\"\n",
    "\n",
    "tool_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), MessagesPlaceholder(\"chat_history\"), (\"user\", \"{input}\")]\n",
    ")\n",
    "print(tool_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.922470Z",
     "iopub.status.busy": "2024-06-26T20:12:35.922182Z",
     "iopub.status.idle": "2024-06-26T20:12:35.934772Z",
     "shell.execute_reply": "2024-06-26T20:12:35.933940Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.922441Z"
    },
    "id": "k89r-nEW17So",
    "outputId": "09bc2ba0-13bc-4e75-b0cb-fd8bebe85160"
   },
   "outputs": [],
   "source": [
    "system_prompt2 = \"\"\"\n",
    "You are a **polite, warm, and professional AI assistant** for Thea, a theater in Athens, Greece.\n",
    "\n",
    "**Thea - Information:**\n",
    "- **Location:** Omonia StreetAthens, Greece (LatLng: 37.9838, 23.7275)\n",
    "- **Website:** https://www.thea.com\n",
    "- **Phone:** +30 210 123 4567\n",
    "- **Instagram:** https://www.instagram.com/thea\n",
    "\n",
    "**Hours of Operation:**\n",
    "- Monday to Friday: 10:00 – 24:00\n",
    "- Saturday & Sunday: 15:00 – 24:00\n",
    "\n",
    "**Ticketing:** Tickets can be purchased online (https://www.thea.com), through the app, or at the counter desk.\n",
    "\n",
    "**Accessibility:** The theater has a wheelchair accessible entrance and seating.\n",
    "\n",
    "**Common User Queries:**\n",
    "- \"What's playing this weekend?\"\n",
    "- \"How can I buy tickets?\"\n",
    "- \"How can I cancel my ticket?\" or \"I want a refund for my ticket\"\n",
    "- \"Where is the theatre located?\"\n",
    "- \"What hours does the theatre work?\"\n",
    "\n",
    "**Important Response Guidelines:**\n",
    "- Always use a warm, polite, professional, and informative tone.\n",
    "- Only cite information you have (do **not** make up or \"hallucinate\" answers).\n",
    "- If you do not know the answer, apologize and politely redirect or suggest the user contact the theater.\n",
    "- Always provide exact URLs (e.g., https://www.thea.com) and phone numbers (+30 210 123 4567) when requested or relevant.\n",
    "- Never include information that is not explicitly provided here.\n",
    "\n",
    "**Instructions:**\n",
    "- Given the user’s input, choose the tool that best fits their request.\n",
    "- Return your answer strictly as a JSON object with **'name'** and **'arguments'** keys.\n",
    "- The **arguments** value should be a dictionary, with argument names as keys and their values filled in appropriately.\n",
    "- **Do not provide explanations or any text outside the JSON.**\n",
    "---\n",
    "\n",
    "**Previous Conversations:**\n",
    "{chat_history}\n",
    "\n",
    "**The user has asked this:**\n",
    "{input}\n",
    "\n",
    "**You have already used a tool that returned this:**\n",
    "\"\"\"\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt2),\n",
    "     (\"user\", \"{output}\")]\n",
    ")\n",
    "print(generation_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.936048Z",
     "iopub.status.busy": "2024-06-26T20:12:35.935788Z",
     "iopub.status.idle": "2024-06-26T20:12:35.949375Z",
     "shell.execute_reply": "2024-06-26T20:12:35.948538Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.936017Z"
    },
    "id": "1qylC3_h17So"
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, TypedDict\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "class ToolCallRequest(TypedDict):\n",
    "    \"\"\"A typed dict that shows the inputs into the invoke_tool function.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    arguments: Dict[str, Any]\n",
    "\n",
    "\n",
    "def invoke_tool(tool_call_request: ToolCallRequest, config: Optional[RunnableConfig] = None):\n",
    "    \"\"\"A function that we can use the perform a tool invocation.\n",
    "\n",
    "    Args:\n",
    "        tool_call_request: a dict that contains the keys name and arguments.\n",
    "            The name must match the name of a tool that exists.\n",
    "            The arguments are the arguments to that tool.\n",
    "        config: This is configuration information that LangChain uses that contains\n",
    "            things like callbacks, metadata, etc.See LCEL documentation about RunnableConfig.\n",
    "\n",
    "    Returns:\n",
    "        output from the requested tool\n",
    "    \"\"\"\n",
    "    tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "    name = tool_call_request[\"name\"]\n",
    "    requested_tool = tool_name_to_tool[name]\n",
    "    return requested_tool.invoke(tool_call_request[\"arguments\"], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.950678Z",
     "iopub.status.busy": "2024-06-26T20:12:35.950442Z",
     "iopub.status.idle": "2024-06-26T20:12:35.962842Z",
     "shell.execute_reply": "2024-06-26T20:12:35.962059Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.950651Z"
    },
    "id": "4mRZH62G17So"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_json_only(text):\n",
    "    \"\"\"\n",
    "    Extract only the first JSON object found in a string.\n",
    "    Useful for isolating JSON output from LLMs with extra text/tokens.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"\\{.*?\\}\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return text  # Fallback: return original if JSON not found\n",
    "\n",
    "def chat(prompt):\n",
    "    \"\"\"\n",
    "    Main chat pipeline:\n",
    "    - Passes prompt through tool selection chain (with JSON extraction/parsing)\n",
    "    - Invokes selected tool\n",
    "    - Generates a final natural language answer using the output of the tool\n",
    "    - Saves chat context in memory (unless unrelated/gibberish)\n",
    "    \"\"\"\n",
    "    print(prompt)\n",
    "    try:\n",
    "        # Tool selection pipeline: prompt → system → LLM → extract JSON → parse JSON → call tool\n",
    "        tool_chain = (\n",
    "            loaded_memory\n",
    "            | tool_prompt\n",
    "            | llama_model\n",
    "            | RunnableLambda(extract_json_only)\n",
    "            | JsonOutputParser()\n",
    "            | invoke_tool\n",
    "        )\n",
    "\n",
    "        # Tool result: expected \"CODE=> output\"\n",
    "        tool_result = tool_chain.invoke(prompt).split(\"=>\", 1)\n",
    "        code = tool_result[0].strip()\n",
    "        tool_output = {'output': tool_result[1].strip()} if len(tool_result) > 1 else {'output': ''}\n",
    "        tool_output['input'] = prompt.get('input', '')\n",
    "\n",
    "        # Generation chain: uses tool output for final answer\n",
    "        generation_chain = loaded_memory | generation_prompt | llama_model\n",
    "        generated_text = generation_chain.invoke(tool_output).replace('`','').replace(\"AI:\", \"\")\n",
    "\n",
    "        # Debugging\n",
    "        print(\"Code:\", code)\n",
    "        print(\"Tool Output:\", tool_output)\n",
    "        print(\"Generated:\", generated_text)\n",
    "\n",
    "        outputs = {'output': generated_text}\n",
    "\n",
    "        # Save chat only if it's a valid exchange\n",
    "        if code not in [\"USER_INPUT_UNRELATED_TO_THEATER\", \"USER_INPUT_NOT_UNDERSTANDABLE\"]:\n",
    "            memory.save_context(prompt, outputs)\n",
    "\n",
    "        return code, generated_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"CAUGHT_EXCEPTION:\", str(e))\n",
    "        return (\n",
    "            \"USER_INPUT_NOT_UNDERSTANDABLE\",\n",
    "            \"I am sorry, I am afraid I do not understand what you want me to do. Please try again.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.964176Z",
     "iopub.status.busy": "2024-06-26T20:12:35.963865Z",
     "iopub.status.idle": "2024-06-26T20:12:35.976988Z",
     "shell.execute_reply": "2024-06-26T20:12:35.976073Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.964146Z"
    },
    "id": "V3lASVU317Sp"
   },
   "outputs": [],
   "source": [
    "def show_history(memory):\n",
    "    print(\"Chat History is as follows: \\n\")\n",
    "    chat_history = memory.buffer\n",
    "    for i in range(0, len(chat_history), 2):\n",
    "        user_message = chat_history[i].content\n",
    "        ai_message = chat_history[i + 1].content\n",
    "        print(f\"User Prompt: {user_message}\")\n",
    "        print(f\"AI: {ai_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.978417Z",
     "iopub.status.busy": "2024-06-26T20:12:35.978082Z",
     "iopub.status.idle": "2024-06-26T20:12:35.986380Z",
     "shell.execute_reply": "2024-06-26T20:12:35.985535Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.978385Z"
    },
    "id": "EgQLGcKv17Sp"
   },
   "outputs": [],
   "source": [
    "def clear_history(memory):\n",
    "    memory.clear()\n",
    "    print(\"Chat history was cleared successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.987711Z",
     "iopub.status.busy": "2024-06-26T20:12:35.987462Z",
     "iopub.status.idle": "2024-06-26T20:12:35.995553Z",
     "shell.execute_reply": "2024-06-26T20:12:35.994813Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.987689Z"
    },
    "id": "DYf9rq2e17Sp",
    "outputId": "ed625074-0a6e-4059-9c16-7ee17ae28b39"
   },
   "outputs": [],
   "source": [
    "show_history(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:35.996819Z",
     "iopub.status.busy": "2024-06-26T20:12:35.996531Z",
     "iopub.status.idle": "2024-06-26T20:12:36.004590Z",
     "shell.execute_reply": "2024-06-26T20:12:36.003737Z",
     "shell.execute_reply.started": "2024-06-26T20:12:35.996795Z"
    },
    "id": "2EWSVcFi17Sp",
    "outputId": "84c50e4a-3af7-47b2-81ac-78e887baee9d"
   },
   "outputs": [],
   "source": [
    "clear_history(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:36.009902Z",
     "iopub.status.busy": "2024-06-26T20:12:36.009577Z",
     "iopub.status.idle": "2024-06-26T20:12:36.014687Z",
     "shell.execute_reply": "2024-06-26T20:12:36.013951Z",
     "shell.execute_reply.started": "2024-06-26T20:12:36.009878Z"
    },
    "id": "p2z1i9Qr17Sp",
    "outputId": "e88002c2-8f2b-4b4a-9a54-ed663ae274ae"
   },
   "outputs": [],
   "source": [
    "inputs = {'input': \"I want to see Romeo and Juliet\"}\n",
    "response = chat(inputs)\n",
    "print(f\"========> {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJnanFpx17Sp"
   },
   "source": [
    "# Connection with Thea App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:36.016026Z",
     "iopub.status.busy": "2024-06-26T20:12:36.015750Z",
     "iopub.status.idle": "2024-06-26T20:12:41.456934Z",
     "shell.execute_reply": "2024-06-26T20:12:41.455670Z",
     "shell.execute_reply.started": "2024-06-26T20:12:36.016002Z"
    },
    "id": "MyXKpSyP17Sp",
    "outputId": "ac80a5da-2e46-42db-b05b-f402eca579dc"
   },
   "outputs": [],
   "source": [
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:41.461248Z",
     "iopub.status.busy": "2024-06-26T20:12:41.460942Z",
     "iopub.status.idle": "2024-06-26T20:12:41.466199Z",
     "shell.execute_reply": "2024-06-26T20:12:41.465157Z",
     "shell.execute_reply.started": "2024-06-26T20:12:41.461220Z"
    },
    "id": "nM6hdbU717Sp"
   },
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from pyngrok import ngrok\n",
    "from flask import request, jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-26T20:12:41.467517Z",
     "iopub.status.busy": "2024-06-26T20:12:41.467231Z"
    },
    "id": "sGq3Vkqb17Sp",
    "outputId": "4e4df30d-f52f-442a-a2f3-7c37206bb1db"
   },
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "ngrok.set_auth_token(user_secrets.get_secret(\"ngrok_token\"))\n",
    "public_url = ngrok.connect(5000).public_url\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return \"Hello, World!\"\n",
    "\n",
    "@app.route('/send_message', methods=['POST'])\n",
    "def send_message():\n",
    "    data = request.get_json()\n",
    "    message = data.get('message', '')\n",
    "    global memory\n",
    "\n",
    "    if message == \"CLEAR_HISTORY\":\n",
    "\n",
    "        clear_history(memory)\n",
    "        show_history(memory)\n",
    "\n",
    "    else:\n",
    "        message = {'input': message}\n",
    "\n",
    "        global inputs\n",
    "        inputs = message\n",
    "        print(\"inputs: \", inputs)\n",
    "\n",
    "        if message:\n",
    "            response_message = chat(message)\n",
    "\n",
    "            print(\"response_message:\", response_message)\n",
    "\n",
    "            return jsonify({'code': response_message[0], 'response': response_message[1]})\n",
    "        else:\n",
    "            return jsonify({'error': 'No message provided'}), 400\n",
    "\n",
    "print(f\"To access the global link please click {public_url}\")\n",
    "\n",
    "app.run(port=5000)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5221084,
     "sourceId": 8795073,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 185575671,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0409603a721f4abd938999f1845d1a3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0855f978c0b840228d1820ec05f59ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17a391994b0e48bf87086ef020f4b41d",
      "placeholder": "​",
      "style": "IPY_MODEL_84e142082d814a6a88d7dcb362872f8c",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "1464d99fd8f44145b5cab8ee6e123225": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e7112fa300746cb898cf517a0e36d32",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_598b1be5b98c4d4c83767b55f29a4fc5",
      "value": 2
     }
    },
    "17a391994b0e48bf87086ef020f4b41d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "397b48a3e5014eb68ae3903e26c6ea37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4756317093d846c0a882ef2fbd5cb0eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58fdd4d30a564348bd1c4069de39ae9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b320515a0f6b4ef981e5ddcea48e274e",
      "placeholder": "​",
      "style": "IPY_MODEL_397b48a3e5014eb68ae3903e26c6ea37",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "598b1be5b98c4d4c83767b55f29a4fc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6178927dcff043df894c2d146d38b131": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62bb42ce0ec747e1be7d739dd49ead3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "634f124d6f2b42b3bf9e13f726c18e00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "671a9e2d349344a49762667039bd0d7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "776311f7331a4648915a53c3a2ea79ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7e7112fa300746cb898cf517a0e36d32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84e142082d814a6a88d7dcb362872f8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9390949e3f7342b386c165eea4d15236": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6178927dcff043df894c2d146d38b131",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_776311f7331a4648915a53c3a2ea79ec",
      "value": 2
     }
    },
    "960152c40cc241febdbeaa98b3893d34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0855f978c0b840228d1820ec05f59ea3",
       "IPY_MODEL_1464d99fd8f44145b5cab8ee6e123225",
       "IPY_MODEL_da37e43e8b294a7d8dc64c9b700d6fe3"
      ],
      "layout": "IPY_MODEL_bdcf5774e6434ba685d5ca208a7919d2"
     }
    },
    "a6758ee63c074156bde8b7eaa59240be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58fdd4d30a564348bd1c4069de39ae9c",
       "IPY_MODEL_9390949e3f7342b386c165eea4d15236",
       "IPY_MODEL_e062ec6af90b4a808a536375f3df6e9c"
      ],
      "layout": "IPY_MODEL_4756317093d846c0a882ef2fbd5cb0eb"
     }
    },
    "b320515a0f6b4ef981e5ddcea48e274e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdcf5774e6434ba685d5ca208a7919d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da37e43e8b294a7d8dc64c9b700d6fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_634f124d6f2b42b3bf9e13f726c18e00",
      "placeholder": "​",
      "style": "IPY_MODEL_62bb42ce0ec747e1be7d739dd49ead3a",
      "value": " 2/2 [00:04&lt;00:00,  2.00s/it]"
     }
    },
    "e062ec6af90b4a808a536375f3df6e9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0409603a721f4abd938999f1845d1a3c",
      "placeholder": "​",
      "style": "IPY_MODEL_671a9e2d349344a49762667039bd0d7f",
      "value": " 2/2 [00:04&lt;00:00,  2.06s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
